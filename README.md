# ğŸ”’ Detecting Malicious Prompts for Large Language Models (LLMs)
#It is also part of "Prompter Says": A Linguistic Approach to Understanding and Detecting Jailbreak Attacks Against Large-Language Models paper
[Link](https://dl.acm.org/doi/10.1145/3689217.3690618)

![Project Banner](plot0001_.png)

---

## ğŸ“– Project Overview

Large language models (LLMs) are vulnerable to "jailbreak" prompts that induce undesired or harmful behavior. This project develops a machine learning pipeline to detect such malicious prompts using linguistic analysis and various classifiers, enabling early filtering before prompts reach the models.

---

## ğŸ¯ Objectives

- Collect and preprocess a labeled prompt dataset (benign vs. malicious).
- Extract linguistic features: tokenization, lemmatization, stemming, stopword removal.
- Use vectorizers: CountVectorizer, TF-IDF, and Word2Vec embeddings.
- Train and evaluate classifiers including Logistic Regression, SVM, Random Forest, and others.
- Measure performance with accuracy, precision, recall, and F1-score.

---

## ğŸ—‚ï¸ Project Structure

â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ FinalRawData.csv
â”‚ â””â”€â”€ FinalCleanedData.csv
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ cs205_project_data_clean.ipynb
â”‚ â””â”€â”€ cs205_project_classifiers.ipynb
â”œâ”€â”€ README.md



---

## ğŸ§¹ Data Preprocessing

- Tokenize text with `nltk.RegexpTokenizer`
- Lowercase all words
- Lemmatize using `WordNetLemmatizer`
- Stem using `PorterStemmer`
- Remove English stopwords with NLTK
- Store cleaned text in `cleaned` column

---

## ğŸ’¡ Feature Extraction Methods

| Method            | Description                              |
|-------------------|----------------------------------------|
| CountVectorizer   | Bag-of-words frequency counts          |
| TF-IDF Vectorizer  | Term frequency - inverse document freq |
| Word2Vec Embedding | Semantic word embeddings from training data |

---

## ğŸ¤– Classifiers Evaluated

- Logistic Regression
- Support Vector Machine (SVM)
- Random Forest
- k-Nearest Neighbors (k-NN)
- Naive Bayes
- Decision Tree
- Gradient Boosting
- Extra Trees

---

## ğŸ“Š Evaluation Metrics

- **Accuracy**
- **Precision** (weighted)
- **Recall** (weighted)
- **F1 Score** (weighted)

---

## ğŸš€ How to Run

1. Install dependencies:

```bash
pip install pandas scikit-learn gensim nltk
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

Run data cleaning notebook:

notebooks/cs205_project_data_clean.ipynb

Run model training and evaluation notebook:

notebooks/cs205_project_classifiers.ipynb
